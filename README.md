
# Image Captioning Project - README

## ğŸ“Œ Overview
This project implements an **image captioning system** using an encoderâ€“decoder LSTM architecture trained on the **Flickr8k dataset**.  
It uses **InceptionV3** for image feature extraction and a **Keras LSTM decoder** for caption generation.

---

## ğŸ“‚ Folder Structure
```
evostra_captioning/
â”‚
â”œâ”€â”€ features/                 # Pre-extracted image features (.npy)
â”œâ”€â”€ Flickr8k_text/            # Captions & split files
â”œâ”€â”€ models/
â”‚      â”œâ”€â”€ final_model.keras  # Best model for inference
â”‚      â”œâ”€â”€ tokenizer.pkl      # Tokenizer used in training
â”‚      â”œâ”€â”€ model-XX.h5        # Training checkpoints
â”‚
â””â”€â”€ app.py                    # Streamlit inference app
```

---

## ğŸš€ Running the Streamlit App

### 1ï¸âƒ£ Install dependencies
```
pip install tensorflow pillow numpy streamlit
```

### 2ï¸âƒ£ Run Streamlit
```
streamlit run app.py
```

### 3ï¸âƒ£ Upload an image  
The app will:
- Extract features using InceptionV3  
- Feed them into the LSTM decoder  
- Generate a caption  
- Display the output  

---

## âš™ï¸ Inference Requirements
- `final_model.keras`  
- `tokenizer.pkl`  
- `max_length = 38`  
- InceptionV3 preprocessing for uploaded images  

---

## ğŸ§  Training Summary
- Dataset: Flickr8k  
- Epochs: 20  
- Loss reached ~2.28  
- Pre-extracted features used for efficiency  
- Final model saved in **Keras format (.keras)** for compatibility  

---

## ğŸ“¥ Downloading Models from Colab
```
from google.colab import files
files.download("/content/drive/MyDrive/evostra_captioning/models/final_model.keras")
files.download("/content/drive/MyDrive/evostra_captioning/models/tokenizer.pkl")
```

---

## ğŸ“ Important Notes
- Avoid loading `.h5` in Keras 3 â€” use `.keras` format  
- Ensure correct path in `app.py`  
- Make sure uploaded images are resized properly  

---

## ğŸ‘¤ Author
**Om Yadav**  
Image Captioning â€” AI/ML Project  
